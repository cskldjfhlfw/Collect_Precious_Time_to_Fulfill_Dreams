#!/usr/bin/env python3
"""Generate test data for all databases (PostgreSQL, Neo4j, MongoDB, Redis)."""

import asyncio
import json
import random
from datetime import date, datetime, timedelta
from decimal import Decimal
from typing import List, Dict, Any
from uuid import uuid4

# PostgreSQL imports
from sqlalchemy.ext.asyncio import create_async_engine, AsyncSession
from sqlalchemy.orm import sessionmaker
from sqlalchemy import select

# Neo4j imports
from neo4j import GraphDatabase

# MongoDB imports
from motor.motor_asyncio import AsyncIOMotorClient

# Redis imports
import redis.asyncio as redis

from app.core.config import settings
from app.models.tables import (
    User, Paper, Patent, SoftwareCopyright, Project, Competition,
    Conference, Cooperation, Resource, Relationship, ResourceAchievement,
    Tag, AchievementTag, PaperAuthor, ProjectMilestone, Reminder,
    ResourceUsageLog, ResourceMaintenanceTask, SearchSavedView
)


class MultiDatabaseTestDataGenerator:
    """å¤šæ•°æ®åº“æµ‹è¯•æ•°æ®ç”Ÿæˆå™¨"""
    
    def __init__(self):
        self.pg_engine = None
        self.pg_session = None
        self.neo4j_driver = None
        self.mongo_client = None
        self.mongo_db = None
        self.redis_client = None
        
        # å­˜å‚¨ç”Ÿæˆçš„æ•°æ®IDæ˜ å°„
        self.user_ids = {}
        self.paper_ids = {}
        self.patent_ids = {}
        self.software_ids = {}
        self.project_ids = {}
        self.competition_ids = {}
        self.conference_ids = {}
        self.cooperation_ids = {}
        self.resource_ids = {}
        self.tag_ids = {}
    
    async def connect_databases(self):
        """è¿æ¥æ‰€æœ‰æ•°æ®åº“"""
        print("ğŸ”Œ è¿æ¥æ•°æ®åº“...")
        
        # PostgreSQL
        if settings.postgres_enabled:
            self.pg_engine = create_async_engine(str(settings.postgres_dsn))
            async_session = sessionmaker(self.pg_engine, class_=AsyncSession, expire_on_commit=False)
            self.pg_session = async_session()
            print("âœ… PostgreSQL è¿æ¥æˆåŠŸ")
        
        # Neo4j
        if settings.neo4j_enabled:
            self.neo4j_driver = GraphDatabase.driver(
                settings.neo4j_uri,
                auth=(settings.neo4j_user, settings.neo4j_password)
            )
            self.neo4j_database = settings.neo4j_database or "neo4j"
            print(f"âœ… Neo4j è¿æ¥æˆåŠŸ (æ•°æ®åº“: {self.neo4j_database})")
        
        # MongoDB
        if settings.mongo_enabled:
            self.mongo_client = AsyncIOMotorClient(settings.mongo_dsn)
            self.mongo_db = self.mongo_client[settings.mongo_database]
            print("âœ… MongoDB è¿æ¥æˆåŠŸ")
        
        # Redis
        if settings.redis_enabled:
            self.redis_client = redis.from_url(str(settings.redis_dsn))
            print("âœ… Redis è¿æ¥æˆåŠŸ")
    
    async def close_connections(self):
        """å…³é—­æ‰€æœ‰æ•°æ®åº“è¿æ¥"""
        print("ğŸ”Œ å…³é—­æ•°æ®åº“è¿æ¥...")
        
        if self.pg_session:
            await self.pg_session.close()
        if self.pg_engine:
            await self.pg_engine.dispose()
        if self.neo4j_driver:
            self.neo4j_driver.close()
        if self.mongo_client:
            self.mongo_client.close()
        if self.redis_client:
            await self.redis_client.aclose()
    
    async def generate_postgresql_data(self):
        """ç”ŸæˆPostgreSQLæµ‹è¯•æ•°æ®"""
        if not self.pg_session:
            return
        
        print("ğŸ“Š ç”ŸæˆPostgreSQLæ•°æ®...")
        
        # åˆ›å»ºç”¨æˆ·
        users_data = [
            {"username": "admin", "email": "admin@research.edu", "role": "admin"},
            {"username": "zhang_wei", "email": "zhang.wei@research.edu", "role": "researcher"},
            {"username": "li_ming", "email": "li.ming@research.edu", "role": "researcher"},
            {"username": "wang_fang", "email": "wang.fang@research.edu", "role": "student"},
        ]
        
        for user_data in users_data:
            # æ£€æŸ¥ç”¨æˆ·æ˜¯å¦å·²å­˜åœ¨
            existing = await self.pg_session.execute(
                select(User).where(User.username == user_data["username"])
            )
            existing_user = existing.scalar_one_or_none()
            
            if not existing_user:
                user = User(
                    username=user_data["username"],
                    email=user_data["email"],
                    password_hash="$2b$12$dummy_hash_for_testing",
                    role=user_data["role"]
                )
                self.pg_session.add(user)
                await self.pg_session.commit()
                await self.pg_session.refresh(user)
                self.user_ids[user_data["username"]] = str(user.id)
            else:
                self.user_ids[user_data["username"]] = str(existing_user.id)
        
        print(f"âœ… PostgreSQL: åˆ›å»ºäº† {len(users_data)} ä¸ªç”¨æˆ·")
    
    def generate_neo4j_data(self):
        """ç”ŸæˆNeo4jæµ‹è¯•æ•°æ®"""
        if not self.neo4j_driver:
            return
        
        print("ğŸ•¸ï¸  ç”ŸæˆNeo4jæ•°æ®...")
        
        with self.neo4j_driver.session(database=self.neo4j_database) as session:
            # æ¸…ç†ç°æœ‰æ•°æ®
            session.run("MATCH (n) DETACH DELETE n")
            
            # åˆ›å»ºç ”ç©¶äººå‘˜èŠ‚ç‚¹
            researchers = [
                {"name": "å¼ ä¼Ÿ", "title": "æ•™æˆ", "field": "äººå·¥æ™ºèƒ½", "experience": 15},
                {"name": "ææ˜", "title": "å‰¯æ•™æˆ", "field": "æœºå™¨å­¦ä¹ ", "experience": 10},
                {"name": "ç‹èŠ³", "title": "è®²å¸ˆ", "field": "æ·±åº¦å­¦ä¹ ", "experience": 5},
                {"name": "é™ˆæµ©", "title": "ç ”ç©¶ç”Ÿ", "field": "è®¡ç®—æœºè§†è§‰", "experience": 2},
            ]
            
            for researcher in researchers:
                session.run(
                    "CREATE (r:Researcher {name: $name, title: $title, field: $field, experience: $experience})",
                    **researcher
                )
            
            # åˆ›å»ºç ”ç©¶é¢†åŸŸèŠ‚ç‚¹
            fields = ["äººå·¥æ™ºèƒ½", "æœºå™¨å­¦ä¹ ", "æ·±åº¦å­¦ä¹ ", "è®¡ç®—æœºè§†è§‰", "è‡ªç„¶è¯­è¨€å¤„ç†", "åŒºå—é“¾"]
            for field in fields:
                session.run("CREATE (f:Field {name: $name})", name=field)
            
            # åˆ›å»ºé¡¹ç›®èŠ‚ç‚¹
            projects = [
                {"name": "æ™ºèƒ½åˆ¶é€ å…³é”®æŠ€æœ¯ç ”ç©¶", "budget": 2000000, "status": "è¿›è¡Œä¸­", "type": "research"},
                {"name": "æ–°ä¸€ä»£äººå·¥æ™ºèƒ½ç®—æ³•ä¼˜åŒ–", "budget": 800000, "status": "è¿›è¡Œä¸­", "type": "research"},
                {"name": "åŒºå—é“¾å®‰å…¨æŠ€æœ¯äº§ä¸šåŒ–åº”ç”¨", "budget": 1500000, "status": "è¿›è¡Œä¸­", "type": "application"},
            ]
            
            for project in projects:
                session.run(
                    "CREATE (p:Project {name: $name, budget: $budget, status: $status, type: $type})",
                    **project
                )
            
            # åˆ›å»ºæœºæ„èŠ‚ç‚¹
            institutions = [
                {"name": "æ¸…åå¤§å­¦", "type": "university", "country": "ä¸­å›½"},
                {"name": "åä¸ºæŠ€æœ¯æœ‰é™å…¬å¸", "type": "enterprise", "country": "ä¸­å›½"},
                {"name": "MIT Media Lab", "type": "research_institute", "country": "ç¾å›½"},
                {"name": "ç§‘å¤§è®¯é£è‚¡ä»½æœ‰é™å…¬å¸", "type": "enterprise", "country": "ä¸­å›½"},
            ]
            
            for institution in institutions:
                session.run(
                    "CREATE (i:Institution {name: $name, type: $type, country: $country})",
                    **institution
                )
            
            # åˆ›å»ºä¼šè®®èŠ‚ç‚¹
            conferences = [
                {"name": "IJCAI 2023", "location": "åŒ—äº¬", "level": "Aç±»", "year": 2023},
                {"name": "CBTAS 2023", "location": "ä¸Šæµ·", "level": "å›½å®¶çº§", "year": 2023},
                {"name": "CCL 2023", "location": "æ·±åœ³", "level": "Bç±»", "year": 2023},
            ]
            
            for conf in conferences:
                session.run(
                    "CREATE (c:Conference {name: $name, location: $location, level: $level, year: $year})",
                    **conf
                )
            
            # åˆ›å»ºå…³ç³»
            relationships = [
                # ç ”ç©¶äººå‘˜ä¸“é•¿é¢†åŸŸ
                ("MATCH (r:Researcher {name: 'å¼ ä¼Ÿ'}), (f:Field {name: 'äººå·¥æ™ºèƒ½'}) CREATE (r)-[:SPECIALIZES_IN]->(f)", {}),
                ("MATCH (r:Researcher {name: 'ææ˜'}), (f:Field {name: 'æœºå™¨å­¦ä¹ '}) CREATE (r)-[:SPECIALIZES_IN]->(f)", {}),
                ("MATCH (r:Researcher {name: 'ç‹èŠ³'}), (f:Field {name: 'æ·±åº¦å­¦ä¹ '}) CREATE (r)-[:SPECIALIZES_IN]->(f)", {}),
                
                # é¡¹ç›®è´Ÿè´£äºº
                ("MATCH (r:Researcher {name: 'å¼ ä¼Ÿ'}), (p:Project {name: 'æ™ºèƒ½åˆ¶é€ å…³é”®æŠ€æœ¯ç ”ç©¶'}) CREATE (r)-[:LEADS]->(p)", {}),
                ("MATCH (r:Researcher {name: 'ææ˜'}), (p:Project {name: 'æ–°ä¸€ä»£äººå·¥æ™ºèƒ½ç®—æ³•ä¼˜åŒ–'}) CREATE (r)-[:LEADS]->(p)", {}),
                
                # é¡¹ç›®åˆä½œ
                ("MATCH (r:Researcher {name: 'ç‹èŠ³'}), (p:Project {name: 'æ™ºèƒ½åˆ¶é€ å…³é”®æŠ€æœ¯ç ”ç©¶'}) CREATE (r)-[:PARTICIPATES_IN]->(p)", {}),
                ("MATCH (r:Researcher {name: 'é™ˆæµ©'}), (p:Project {name: 'æ–°ä¸€ä»£äººå·¥æ™ºèƒ½ç®—æ³•ä¼˜åŒ–'}) CREATE (r)-[:PARTICIPATES_IN]->(p)", {}),
                
                # ç ”ç©¶äººå‘˜åˆä½œå…³ç³»
                ("MATCH (r1:Researcher {name: 'å¼ ä¼Ÿ'}), (r2:Researcher {name: 'ææ˜'}) CREATE (r1)-[:COLLABORATES_WITH {since: 2020, papers: 5}]->(r2)", {}),
                ("MATCH (r1:Researcher {name: 'ææ˜'}), (r2:Researcher {name: 'ç‹èŠ³'}) CREATE (r1)-[:COLLABORATES_WITH {since: 2021, papers: 3}]->(r2)", {}),
                
                # ç ”ç©¶äººå‘˜æ‰€å±æœºæ„
                ("MATCH (r:Researcher {name: 'å¼ ä¼Ÿ'}), (i:Institution {name: 'æ¸…åå¤§å­¦'}) CREATE (r)-[:AFFILIATED_WITH]->(i)", {}),
                ("MATCH (r:Researcher {name: 'ææ˜'}), (i:Institution {name: 'æ¸…åå¤§å­¦'}) CREATE (r)-[:AFFILIATED_WITH]->(i)", {}),
                ("MATCH (r:Researcher {name: 'ç‹èŠ³'}), (i:Institution {name: 'æ¸…åå¤§å­¦'}) CREATE (r)-[:AFFILIATED_WITH]->(i)", {}),
                
                # æœºæ„åˆä½œå…³ç³»
                ("MATCH (i1:Institution {name: 'æ¸…åå¤§å­¦'}), (i2:Institution {name: 'åä¸ºæŠ€æœ¯æœ‰é™å…¬å¸'}) CREATE (i1)-[:COOPERATES_WITH {type: 'æ ¡ä¼åˆä½œ', start_year: 2023}]->(i2)", {}),
                ("MATCH (i1:Institution {name: 'æ¸…åå¤§å­¦'}), (i2:Institution {name: 'MIT Media Lab'}) CREATE (i1)-[:COOPERATES_WITH {type: 'å­¦æœ¯äº¤æµ', start_year: 2023}]->(i2)", {}),
                ("MATCH (i1:Institution {name: 'æ¸…åå¤§å­¦'}), (i2:Institution {name: 'ç§‘å¤§è®¯é£è‚¡ä»½æœ‰é™å…¬å¸'}) CREATE (i1)-[:COOPERATES_WITH {type: 'äº§å­¦ç ”åˆä½œ', start_year: 2023}]->(i2)", {}),
                
                # ç ”ç©¶äººå‘˜å‚åŠ ä¼šè®®
                ("MATCH (r:Researcher {name: 'å¼ ä¼Ÿ'}), (c:Conference {name: 'IJCAI 2023'}) CREATE (r)-[:ATTENDED {role: 'speaker'}]->(c)", {}),
                ("MATCH (r:Researcher {name: 'ç‹èŠ³'}), (c:Conference {name: 'CBTAS 2023'}) CREATE (r)-[:ATTENDED {role: 'poster'}]->(c)", {}),
                ("MATCH (r:Researcher {name: 'ææ˜'}), (c:Conference {name: 'CCL 2023'}) CREATE (r)-[:ATTENDED {role: 'speaker'}]->(c)", {}),
            ]
            
            for query, params in relationships:
                session.run(query, **params)
        
        print("âœ… Neo4j: åˆ›å»ºäº†ç ”ç©¶äººå‘˜ã€é¡¹ç›®ã€æœºæ„ã€ä¼šè®®å’Œå…³ç³»ç½‘ç»œ")
    
    async def generate_mongodb_data(self):
        """ç”ŸæˆMongoDBæµ‹è¯•æ•°æ®"""
        if self.mongo_db is None:
            return
        
        print("ğŸƒ ç”ŸæˆMongoDBæ•°æ®...")
        
        # è®ºæ–‡é›†åˆ
        papers_collection = self.mongo_db.papers
        papers_data = [
            {
                "_id": str(uuid4()),
                "title": "åŸºäºæ·±åº¦å­¦ä¹ çš„å›¾åƒè¯†åˆ«ç®—æ³•ç ”ç©¶",
                "authors": ["å¼ ä¼Ÿ", "ææ˜"],
                "journal": "è®¡ç®—æœºå­¦æŠ¥",
                "year": 2023,
                "keywords": ["æ·±åº¦å­¦ä¹ ", "å›¾åƒè¯†åˆ«", "å·ç§¯ç¥ç»ç½‘ç»œ"],
                "abstract": "æœ¬æ–‡æå‡ºäº†ä¸€ç§åŸºäºæ·±åº¦å­¦ä¹ çš„å›¾åƒè¯†åˆ«ç®—æ³•...",
                "citations": 25,
                "impact_factor": 3.85,
                "full_text": {
                    "introduction": "éšç€äººå·¥æ™ºèƒ½æŠ€æœ¯çš„å¿«é€Ÿå‘å±•...",
                    "methodology": "æœ¬ç ”ç©¶é‡‡ç”¨æ”¹è¿›çš„å·ç§¯ç¥ç»ç½‘ç»œ...",
                    "results": "å®éªŒç»“æœè¡¨æ˜ï¼Œæå‡ºçš„ç®—æ³•...",
                    "conclusion": "æœ¬æ–‡æˆåŠŸå¼€å‘äº†ä¸€ç§æ–°çš„å›¾åƒè¯†åˆ«ç®—æ³•..."
                },
                "metadata": {
                    "created_at": datetime.now(),
                    "updated_at": datetime.now(),
                    "status": "published",
                    "peer_reviewed": True
                }
            },
            {
                "_id": str(uuid4()),
                "title": "åŒºå—é“¾æŠ€æœ¯åœ¨ä¾›åº”é“¾ç®¡ç†ä¸­çš„åº”ç”¨",
                "authors": ["ç‹èŠ³", "é™ˆæµ©"],
                "journal": "è½¯ä»¶å­¦æŠ¥",
                "year": 2023,
                "keywords": ["åŒºå—é“¾", "ä¾›åº”é“¾", "æ™ºèƒ½åˆçº¦"],
                "abstract": "ç ”ç©¶äº†åŒºå—é“¾æŠ€æœ¯åœ¨ä¾›åº”é“¾ç®¡ç†ä¸­çš„åº”ç”¨åœºæ™¯...",
                "citations": 18,
                "impact_factor": 2.94,
                "full_text": {
                    "introduction": "ä¾›åº”é“¾ç®¡ç†æ˜¯ç°ä»£ä¼ä¸šè¿è¥çš„æ ¸å¿ƒ...",
                    "methodology": "æœ¬ç ”ç©¶è®¾è®¡äº†åŸºäºåŒºå—é“¾çš„ä¾›åº”é“¾ç³»ç»Ÿ...",
                    "results": "ç³»ç»Ÿæµ‹è¯•æ˜¾ç¤ºï¼ŒåŒºå—é“¾æŠ€æœ¯èƒ½å¤Ÿ...",
                    "conclusion": "åŒºå—é“¾æŠ€æœ¯ä¸ºä¾›åº”é“¾ç®¡ç†æä¾›äº†æ–°çš„è§£å†³æ–¹æ¡ˆ..."
                },
                "metadata": {
                    "created_at": datetime.now(),
                    "updated_at": datetime.now(),
                    "status": "published",
                    "peer_reviewed": True
                }
            }
        ]
        
        await papers_collection.insert_many(papers_data)
        
        # ç ”ç©¶æ•°æ®é›†åˆ
        datasets_collection = self.mongo_db.datasets
        datasets_data = [
            {
                "_id": str(uuid4()),
                "name": "ImageNet-Research",
                "description": "ç”¨äºå›¾åƒè¯†åˆ«ç ”ç©¶çš„å¤§å‹æ•°æ®é›†",
                "size_gb": 150.5,
                "format": "JPEG",
                "samples_count": 1000000,
                "labels": ["åŠ¨ç‰©", "æ¤ç‰©", "å»ºç­‘", "äº¤é€šå·¥å…·"],
                "access_level": "public",
                "download_count": 2500,
                "created_by": "å¼ ä¼Ÿ",
                "created_at": datetime.now(),
                "tags": ["è®¡ç®—æœºè§†è§‰", "æ·±åº¦å­¦ä¹ ", "å›¾åƒåˆ†ç±»"]
            },
            {
                "_id": str(uuid4()),
                "name": "Blockchain-Transactions",
                "description": "åŒºå—é“¾äº¤æ˜“æ•°æ®é›†",
                "size_gb": 45.2,
                "format": "JSON",
                "samples_count": 500000,
                "access_level": "restricted",
                "download_count": 150,
                "created_by": "ç‹èŠ³",
                "created_at": datetime.now(),
                "tags": ["åŒºå—é“¾", "é‡‘èç§‘æŠ€", "æ•°æ®æŒ–æ˜"]
            }
        ]
        
        await datasets_collection.insert_many(datasets_data)
        
        # å®éªŒè®°å½•é›†åˆ
        experiments_collection = self.mongo_db.experiments
        experiments_data = [
            {
                "_id": str(uuid4()),
                "experiment_name": "CNNæ¨¡å‹æ€§èƒ½æµ‹è¯•",
                "researcher": "ææ˜",
                "start_time": datetime.now() - timedelta(days=5),
                "end_time": datetime.now() - timedelta(days=2),
                "parameters": {
                    "learning_rate": 0.001,
                    "batch_size": 32,
                    "epochs": 100,
                    "optimizer": "Adam"
                },
                "results": {
                    "accuracy": 0.95,
                    "precision": 0.93,
                    "recall": 0.94,
                    "f1_score": 0.935
                },
                "notes": "æ¨¡å‹åœ¨éªŒè¯é›†ä¸Šè¡¨ç°è‰¯å¥½ï¼Œå‡†ç¡®ç‡è¾¾åˆ°95%",
                "status": "completed"
            }
        ]
        
        await experiments_collection.insert_many(experiments_data)
        
        # ä¼šè®®èµ„æ–™é›†åˆ
        conferences_collection = self.mongo_db.conference_materials
        conferences_data = [
            {
                "_id": str(uuid4()),
                "conference_name": "IJCAI 2023",
                "paper_title": "åŸºäºæ·±åº¦å­¦ä¹ çš„å›¾åƒè¯†åˆ«ç®—æ³•ç ”ç©¶",
                "presenter": "å¼ ä¼Ÿ",
                "presentation_type": "oral",
                "slides_url": "https://storage.research.edu/slides/ijcai2023_zhang.pdf",
                "video_url": "https://video.research.edu/ijcai2023_zhang.mp4",
                "qa_summary": "ä¸ä¼šè€…å¯¹ç®—æ³•çš„åˆ›æ–°æ€§ç»™äºˆé«˜åº¦è¯„ä»·ï¼Œè®¨è®ºäº†å®é™…åº”ç”¨åœºæ™¯ã€‚",
                "attendance": 150,
                "feedback_score": 4.8,
                "created_at": datetime.now()
            },
            {
                "_id": str(uuid4()),
                "conference_name": "CBTAS 2023",
                "paper_title": "åŒºå—é“¾æŠ€æœ¯åœ¨ä¾›åº”é“¾ç®¡ç†ä¸­çš„åº”ç”¨",
                "presenter": "ç‹èŠ³",
                "presentation_type": "poster",
                "poster_url": "https://storage.research.edu/posters/cbtas2023_wang.pdf",
                "qa_summary": "ä¼ä¸šä»£è¡¨å¯¹åŒºå—é“¾åœ¨ä¾›åº”é“¾ä¸­çš„åº”ç”¨å‰æ™¯è¡¨ç¤ºæµ“åšå…´è¶£ã€‚",
                "attendance": 80,
                "feedback_score": 4.5,
                "created_at": datetime.now()
            }
        ]
        
        await conferences_collection.insert_many(conferences_data)
        
        # åˆä½œé¡¹ç›®æ–‡æ¡£é›†åˆ
        cooperation_docs_collection = self.mongo_db.cooperation_documents
        cooperation_docs_data = [
            {
                "_id": str(uuid4()),
                "cooperation_name": "æ ¡ä¼åˆä½œ-æ™ºèƒ½åˆ¶é€ è”åˆå®éªŒå®¤",
                "partner": "åä¸ºæŠ€æœ¯æœ‰é™å…¬å¸",
                "documents": [
                    {"type": "åˆä½œåè®®", "url": "/docs/agreements/huawei_agreement.pdf", "upload_date": datetime.now()},
                    {"type": "æŠ€æœ¯æ–¹æ¡ˆ", "url": "/docs/proposals/ai_manufacturing.pdf", "upload_date": datetime.now()},
                    {"type": "è¿›åº¦æŠ¥å‘Š", "url": "/docs/reports/2023_q3_report.pdf", "upload_date": datetime.now()}
                ],
                "meetings": [
                    {"date": datetime.now() - timedelta(days=30), "topic": "é¡¹ç›®å¯åŠ¨ä¼š", "attendees": ["å¼ ä¼Ÿ", "åä¸ºä»£è¡¨"]},
                    {"date": datetime.now() - timedelta(days=15), "topic": "æŠ€æœ¯äº¤æµä¼š", "attendees": ["å¼ ä¼Ÿ", "ææ˜", "åä¸ºæŠ€æœ¯å›¢é˜Ÿ"]}
                ],
                "status": "active"
            },
            {
                "_id": str(uuid4()),
                "cooperation_name": "å›½é™…åˆä½œ-ä¸­ç¾åŒºå—é“¾æŠ€æœ¯è”åˆç ”ç©¶",
                "partner": "MIT Media Lab",
                "documents": [
                    {"type": "MOU", "url": "/docs/agreements/mit_mou.pdf", "upload_date": datetime.now()},
                    {"type": "ç ”ç©¶è®¡åˆ’", "url": "/docs/proposals/blockchain_research.pdf", "upload_date": datetime.now()}
                ],
                "meetings": [
                    {"date": datetime.now() - timedelta(days=60), "topic": "é¡¹ç›®å¯åŠ¨è§†é¢‘ä¼šè®®", "attendees": ["ç‹èŠ³", "MITæ•™æˆ"]}
                ],
                "status": "active"
            }
        ]
        
        await cooperation_docs_collection.insert_many(cooperation_docs_data)
        
        # ä¸“åˆ©æ–‡æ¡£é›†åˆ
        patents_collection = self.mongo_db.patent_documents
        patents_data = [
            {
                "_id": str(uuid4()),
                "patent_title": "ä¸€ç§åŸºäºäººå·¥æ™ºèƒ½çš„å›¾åƒå¤„ç†ç³»ç»ŸåŠæ–¹æ³•",
                "patent_number": "CN202310123456.7",
                "full_text": {
                    "abstract": "æœ¬å‘æ˜å…¬å¼€äº†ä¸€ç§åŸºäºäººå·¥æ™ºèƒ½çš„å›¾åƒå¤„ç†ç³»ç»ŸåŠæ–¹æ³•...",
                    "claims": "1. ä¸€ç§åŸºäºäººå·¥æ™ºèƒ½çš„å›¾åƒå¤„ç†ç³»ç»Ÿï¼Œå…¶ç‰¹å¾åœ¨äº...",
                    "description": "æŠ€æœ¯é¢†åŸŸï¼šæœ¬å‘æ˜æ¶‰åŠäººå·¥æ™ºèƒ½å’Œå›¾åƒå¤„ç†æŠ€æœ¯é¢†åŸŸ..."
                },
                "figures": [
                    {"figure_num": 1, "caption": "ç³»ç»Ÿæ¶æ„å›¾", "url": "/patents/figs/fig1.png"},
                    {"figure_num": 2, "caption": "ç®—æ³•æµç¨‹å›¾", "url": "/patents/figs/fig2.png"}
                ],
                "citations": ["CN201810123456.7", "US20190123456A1"],
                "status": "granted",
                "created_at": datetime.now()
            }
        ]
        
        await patents_collection.insert_many(patents_data)
        
        # èµ„æºä½¿ç”¨æ—¥å¿—é›†åˆ
        resource_logs_collection = self.mongo_db.resource_usage_logs
        resource_logs_data = [
            {
                "_id": str(uuid4()),
                "resource_name": "GPUè®¡ç®—é›†ç¾¤",
                "user": "å¼ ä¼Ÿ",
                "task": "å›¾åƒè¯†åˆ«æ¨¡å‹è®­ç»ƒ",
                "start_time": datetime.now() - timedelta(hours=5),
                "end_time": datetime.now() - timedelta(hours=2),
                "gpu_hours": 48,
                "memory_used_gb": 512,
                "status": "completed"
            },
            {
                "_id": str(uuid4()),
                "resource_name": "GPUè®¡ç®—é›†ç¾¤",
                "user": "ææ˜",
                "task": "NLPæ¨¡å‹å¾®è°ƒ",
                "start_time": datetime.now() - timedelta(hours=3),
                "end_time": None,
                "gpu_hours": 12,
                "memory_used_gb": 256,
                "status": "running"
            }
        ]
        
        await resource_logs_collection.insert_many(resource_logs_data)
        
        print("âœ… MongoDB: åˆ›å»ºäº†è®ºæ–‡ã€æ•°æ®é›†ã€å®éªŒè®°å½•ã€ä¼šè®®èµ„æ–™ã€åˆä½œæ–‡æ¡£ã€ä¸“åˆ©æ–‡æ¡£å’Œèµ„æºæ—¥å¿—")
    
    async def generate_redis_data(self):
        """ç”ŸæˆRedisæµ‹è¯•æ•°æ®"""
        if not self.redis_client:
            return
        
        print("ğŸ”´ ç”ŸæˆRedisæ•°æ®...")
        
        # ç”¨æˆ·ä¼šè¯æ•°æ®
        sessions = {
            "session:admin": json.dumps({
                "user_id": self.user_ids.get("admin", "unknown"),
                "username": "admin",
                "role": "admin",
                "login_time": datetime.now().isoformat(),
                "last_activity": datetime.now().isoformat(),
                "permissions": ["read", "write", "admin"]
            }),
            "session:zhang_wei": json.dumps({
                "user_id": self.user_ids.get("zhang_wei", "unknown"),
                "username": "zhang_wei",
                "role": "researcher",
                "login_time": (datetime.now() - timedelta(hours=2)).isoformat(),
                "last_activity": datetime.now().isoformat(),
                "permissions": ["read", "write"]
            })
        }
        
        for key, value in sessions.items():
            await self.redis_client.setex(key, 3600, value)  # 1å°æ—¶è¿‡æœŸ
        
        # ç³»ç»Ÿç»Ÿè®¡æ•°æ®
        stats = {
            "stats:papers:total": 25,
            "stats:papers:published": 20,
            "stats:papers:draft": 5,
            "stats:users:total": 15,
            "stats:users:active": 12,
            "stats:projects:total": 8,
            "stats:projects:ongoing": 5,
            "stats:downloads:today": 45,
            "stats:api_calls:today": 1250
        }
        
        for key, value in stats.items():
            await self.redis_client.set(key, value)
        
        # ç¼“å­˜çƒ­é—¨æœç´¢å…³é”®è¯
        popular_keywords = [
            "äººå·¥æ™ºèƒ½", "æœºå™¨å­¦ä¹ ", "æ·±åº¦å­¦ä¹ ", "åŒºå—é“¾", 
            "è®¡ç®—æœºè§†è§‰", "è‡ªç„¶è¯­è¨€å¤„ç†", "æ•°æ®æŒ–æ˜"
        ]
        
        for i, keyword in enumerate(popular_keywords):
            await self.redis_client.zadd("popular_keywords", {keyword: len(popular_keywords) - i})
        
        # ç¼“å­˜æœ€è¿‘æ´»åŠ¨
        recent_activities = [
            "å¼ ä¼Ÿå‘è¡¨äº†æ–°è®ºæ–‡ã€ŠåŸºäºæ·±åº¦å­¦ä¹ çš„å›¾åƒè¯†åˆ«ç®—æ³•ç ”ç©¶ã€‹",
            "ææ˜åˆ›å»ºäº†æ–°é¡¹ç›®ã€Šæ–°ä¸€ä»£äººå·¥æ™ºèƒ½ç®—æ³•ä¼˜åŒ–ã€‹",
            "ç‹èŠ³ä¸Šä¼ äº†æ–°æ•°æ®é›†ã€ŠåŒºå—é“¾äº¤æ˜“æ•°æ®ã€‹",
            "é™ˆæµ©å®Œæˆäº†å®éªŒã€ŠCNNæ¨¡å‹æ€§èƒ½æµ‹è¯•ã€‹"
        ]
        
        for activity in recent_activities:
            await self.redis_client.lpush("recent_activities", activity)
        
        # è®¾ç½®è¿‡æœŸæ—¶é—´ï¼ˆ24å°æ—¶ï¼‰
        await self.redis_client.expire("recent_activities", 86400)
        
        # ç ”ç©¶äººå‘˜æ’è¡Œæ¦œï¼ˆæŒ‰è®ºæ–‡æ•°é‡ï¼‰
        researcher_rankings = {
            "å¼ ä¼Ÿ": 25,
            "ææ˜": 18,
            "ç‹èŠ³": 15,
            "é™ˆæµ©": 8
        }
        
        for researcher, score in researcher_rankings.items():
            await self.redis_client.zadd("researcher_rankings:papers", {researcher: score})
        
        # é¡¹ç›®è¿›åº¦ç¼“å­˜
        project_progress = {
            "project:æ™ºèƒ½åˆ¶é€ å…³é”®æŠ€æœ¯ç ”ç©¶": json.dumps({
                "progress_percentage": 65,
                "current_phase": "ä¸­æœŸè¯„ä¼°",
                "next_milestone": "åŸå‹ç³»ç»Ÿå¼€å‘",
                "last_updated": datetime.now().isoformat()
            }),
            "project:æ–°ä¸€ä»£äººå·¥æ™ºèƒ½ç®—æ³•ä¼˜åŒ–": json.dumps({
                "progress_percentage": 45,
                "current_phase": "ç®—æ³•ç ”å‘",
                "next_milestone": "æ€§èƒ½æµ‹è¯•",
                "last_updated": datetime.now().isoformat()
            })
        }
        
        for key, value in project_progress.items():
            await self.redis_client.setex(key, 7200, value)  # 2å°æ—¶è¿‡æœŸ
        
        # é€šçŸ¥é˜Ÿåˆ—
        notifications = [
            json.dumps({"type": "project_milestone", "message": "é¡¹ç›®é‡Œç¨‹ç¢‘å·²å®Œæˆ", "project": "æ™ºèƒ½åˆ¶é€ å…³é”®æŠ€æœ¯ç ”ç©¶", "timestamp": datetime.now().isoformat()}),
            json.dumps({"type": "paper_accepted", "message": "è®ºæ–‡è¢«IJCAI 2024æ¥æ”¶", "author": "å¼ ä¼Ÿ", "timestamp": datetime.now().isoformat()}),
            json.dumps({"type": "resource_available", "message": "GPUé›†ç¾¤èµ„æºå·²é‡Šæ”¾", "resource": "GPUè®¡ç®—é›†ç¾¤", "timestamp": datetime.now().isoformat()}),
        ]
        
        for notification in notifications:
            await self.redis_client.lpush("notifications", notification)
        
        await self.redis_client.expire("notifications", 604800)  # 7å¤©è¿‡æœŸ
        
        # APIé€Ÿç‡é™åˆ¶ï¼ˆæ¯ç”¨æˆ·æ¯å°æ—¶è¯·æ±‚æ¬¡æ•°ï¼‰
        rate_limits = {
            "rate_limit:user:admin": 50,
            "rate_limit:user:zhang_wei": 35,
            "rate_limit:user:li_ming": 28
        }
        
        for key, count in rate_limits.items():
            await self.redis_client.setex(key, 3600, count)
        
        # ç¼“å­˜çƒ­é—¨è®ºæ–‡
        popular_papers = [
            "åŸºäºæ·±åº¦å­¦ä¹ çš„å›¾åƒè¯†åˆ«ç®—æ³•ç ”ç©¶",
            "åŒºå—é“¾æŠ€æœ¯åœ¨ä¾›åº”é“¾ç®¡ç†ä¸­çš„åº”ç”¨ç ”ç©¶",
            "è‡ªç„¶è¯­è¨€å¤„ç†ä¸­çš„é¢„è®­ç»ƒæ¨¡å‹ç ”ç©¶è¿›å±•"
        ]
        
        for i, paper in enumerate(popular_papers):
            await self.redis_client.zadd("popular_papers", {paper: 100 - i * 10})
        
        # åœ¨çº¿ç”¨æˆ·é›†åˆ
        online_users = ["admin", "zhang_wei", "li_ming"]
        for user in online_users:
            await self.redis_client.sadd("online_users", user)
        
        await self.redis_client.expire("online_users", 1800)  # 30åˆ†é’Ÿè¿‡æœŸ
        
        # ç¼“å­˜ä¼šè®®æ—¥ç¨‹
        conference_schedule = {
            "conference:IJCAI2023:day1": json.dumps({
                "date": "2023-08-19",
                "sessions": [
                    {"time": "09:00-10:30", "topic": "Deep Learning"},
                    {"time": "11:00-12:30", "topic": "Computer Vision"}
                ]
            }),
            "conference:IJCAI2023:day2": json.dumps({
                "date": "2023-08-20",
                "sessions": [
                    {"time": "09:00-10:30", "topic": "Natural Language Processing"},
                    {"time": "11:00-12:30", "topic": "Robotics"}
                ]
            })
        }
        
        for key, value in conference_schedule.items():
            await self.redis_client.setex(key, 86400, value)
        
        print("âœ… Redis: åˆ›å»ºäº†ä¼šè¯ã€ç»Ÿè®¡ã€ç¼“å­˜ã€æ’è¡Œæ¦œã€é€šçŸ¥é˜Ÿåˆ—å’Œä»»åŠ¡æ•°æ®")
    
    async def verify_data(self):
        """éªŒè¯ç”Ÿæˆçš„æ•°æ®"""
        print("\nğŸ” éªŒè¯ç”Ÿæˆçš„æ•°æ®...")
        
        # PostgreSQLéªŒè¯
        if self.pg_session:
            user_count = await self.pg_session.execute(select(User))
            users = user_count.scalars().all()
            print(f"ğŸ“Š PostgreSQL: {len(users)} ä¸ªç”¨æˆ·")
        
        # Neo4jéªŒè¯
        if self.neo4j_driver:
            with self.neo4j_driver.session(database=self.neo4j_database) as session:
                result = session.run("MATCH (n) RETURN count(n) as count")
                count = result.single()["count"]
                print(f"ğŸ•¸ï¸  Neo4j: {count} ä¸ªèŠ‚ç‚¹")
        
        # MongoDBéªŒè¯
        if self.mongo_db is not None:
            papers_count = await self.mongo_db.papers.count_documents({})
            datasets_count = await self.mongo_db.datasets.count_documents({})
            experiments_count = await self.mongo_db.experiments.count_documents({})
            conferences_count = await self.mongo_db.conference_materials.count_documents({})
            cooperation_docs_count = await self.mongo_db.cooperation_documents.count_documents({})
            patents_count = await self.mongo_db.patent_documents.count_documents({})
            resource_logs_count = await self.mongo_db.resource_usage_logs.count_documents({})
            print(f"ğŸƒ MongoDB: {papers_count} ç¯‡è®ºæ–‡, {datasets_count} ä¸ªæ•°æ®é›†, {experiments_count} ä¸ªå®éªŒ")
            print(f"           {conferences_count} ä¸ªä¼šè®®èµ„æ–™, {cooperation_docs_count} ä¸ªåˆä½œæ–‡æ¡£, {patents_count} ä¸ªä¸“åˆ©æ–‡æ¡£, {resource_logs_count} æ¡èµ„æºæ—¥å¿—")
        
        # RediséªŒè¯
        if self.redis_client:
            keys = await self.redis_client.keys("*")
            print(f"ğŸ”´ Redis: {len(keys)} ä¸ªé”®å€¼å¯¹")
    
    async def run(self):
        """è¿è¡Œå®Œæ•´çš„æ•°æ®ç”Ÿæˆæµç¨‹"""
        try:
            await self.connect_databases()
            
            print("\n" + "=" * 60)
            print("ğŸš€ å¼€å§‹ç”Ÿæˆå¤šæ•°æ®åº“æµ‹è¯•æ•°æ®")
            print("=" * 60)
            
            await self.generate_postgresql_data()
            self.generate_neo4j_data()
            await self.generate_mongodb_data()
            await self.generate_redis_data()
            
            await self.verify_data()
            
            print("\n" + "=" * 60)
            print("ğŸ‰ å¤šæ•°æ®åº“æµ‹è¯•æ•°æ®ç”Ÿæˆå®Œæˆï¼")
            print("=" * 60)
            
        except Exception as e:
            print(f"ğŸ’¥ æ•°æ®ç”Ÿæˆå¤±è´¥: {e}")
            raise
        finally:
            await self.close_connections()


async def main():
    """ä¸»å‡½æ•°"""
    generator = MultiDatabaseTestDataGenerator()
    await generator.run()


if __name__ == "__main__":
    asyncio.run(main())
